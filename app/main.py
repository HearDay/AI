import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'MemGPT')))

from fastapi import FastAPI, Form
import asyncio
from app.core.database import engine, Base, SessionLocal
from app.models import document
from app.api.endpoints import documents as recommend_router
from app.services.analysis_service import analysis_service
from app.core.prompt_templates import build_open_question_prompt
from app.services.question_generator import generate_question
from app.services import feedback, summary
from app.services.llm import LLMClient  

# ======================================================
# ğŸš€ ì•± ì´ˆê¸°í™”
# ======================================================
app = FastAPI(title="Hearday AI í† ë¡  & ì¶”ì²œ ì‹œìŠ¤í…œ")

@app.on_event("startup")
async def on_startup():
    # 1ï¸âƒ£ DB í…Œì´ë¸” ìƒì„±
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    
    # 2ï¸âƒ£ Faiss ì¸ë±ìŠ¤ ë°±ê·¸ë¼ìš´ë“œ ë¹Œë“œ
    async def _build_faiss_background():
        """ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œì—ì„œ Faiss ì¸ë±ìŠ¤ ë¹Œë“œ"""
        try:
            print("FAISS ë°±ê·¸ë¼ìš´ë“œ ì¸ë±ìŠ¤ ë¹Œë“œ ì‹œì‘...")
            async with SessionLocal() as session:
                await analysis_service.load_and_build_index(session)
            print("FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì™„ë£Œ.")
        except Exception as e:
            print(f"FAISS ì¸ë±ìŠ¤ ë¹Œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    asyncio.create_task(_build_faiss_background())

    # 3ï¸âƒ£ H2O-Danube ëª¨ë¸ ë¡œë“œ
    async def _load_danube_model():
        """
        H2O-Danube-1.8B-chat (Apache-2.0) ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œí•˜ì—¬
        ì‹œì—° ì¤‘ ì¦‰ì‹œ ì‘ë‹µ ê°€ëŠ¥í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
        """
        print("H2O-Danube-1.8B-chat ëª¨ë¸ ë¡œë“œ ì¤‘... (ì•½ 1ë¶„ ë‚´ì™¸ ì†Œìš” ì˜ˆìƒ)")
        global _llm_client
        
        _llm_client = await asyncio.to_thread(LLMClient)
        print("âœ… H2O-Danube ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. ì‹œì—° ì¤‘ ì¦‰ì‹œ ì‘ë‹µ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    asyncio.create_task(_load_danube_model())


# ======================================================
# ğŸ”— ë¼ìš°í„° ë“±ë¡
# ======================================================
app.include_router(recommend_router.router)
app.include_router(feedback.router)
app.include_router(summary.router)

# ======================================================
# ğŸŒ ê¸°ë³¸ ë¼ìš°íŠ¸
# ======================================================
@app.get("/")
def read_root():
    return {"message": "Hearday AI í† ë¡  & ì¶”ì²œ API ì„œë²„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤."}

@app.get("/health")
def health():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {"ok": True, "status": "running"}

# ======================================================
# ğŸ’¬ AI í† ë¡  ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
# ======================================================
@app.post("/prompt/preview")
def prompt_preview(level: str = Form("beginner"), summary: str = Form(...)):
    """íƒêµ¬í˜• ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°"""
    return {"level": level, "prompt": build_open_question_prompt(summary, level)}

@app.post("/prompt/question")
def prompt_question(
    mode: str = Form("open"),
    level: str = Form("beginner"),
    context: str = Form(...),
):
    """LLM ê¸°ë°˜ ë‰´ìŠ¤ í† ë¡  ì§ˆë¬¸ ìƒì„± (H2O-Danube ê¸°ë°˜)"""
    question = generate_question(context, mode=mode, level=level)
    return {"mode": mode, "level": level, "question": question}
